{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6239f71",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-08-22T23:33:51.133758Z",
     "iopub.status.busy": "2022-08-22T23:33:51.132520Z",
     "iopub.status.idle": "2022-08-22T23:33:53.549721Z",
     "shell.execute_reply": "2022-08-22T23:33:53.548310Z"
    },
    "papermill": {
     "duration": 2.427081,
     "end_time": "2022-08-22T23:33:53.552717",
     "exception": false,
     "start_time": "2022-08-22T23:33:51.125636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import cv2\n",
    "import time\n",
    "import argparse\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ed671be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T23:33:53.561914Z",
     "iopub.status.busy": "2022-08-22T23:33:53.561466Z",
     "iopub.status.idle": "2022-08-22T23:33:53.566748Z",
     "shell.execute_reply": "2022-08-22T23:33:53.565314Z"
    },
    "papermill": {
     "duration": 0.012624,
     "end_time": "2022-08-22T23:33:53.569397",
     "exception": false,
     "start_time": "2022-08-22T23:33:53.556773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "VALID = False # for validation\n",
    "TEST = True # for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c534f4d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-08-22T23:33:53.578921Z",
     "iopub.status.busy": "2022-08-22T23:33:53.577705Z",
     "iopub.status.idle": "2022-08-22T23:40:01.453902Z",
     "shell.execute_reply": "2022-08-22T23:40:01.452314Z"
    },
    "papermill": {
     "duration": 367.884722,
     "end_time": "2022-08-22T23:40:01.457770",
     "exception": false,
     "start_time": "2022-08-22T23:33:53.573048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/dfl-bundesliga-data-shootout/test/019d5b34_0.mp4\n",
      "../input/dfl-bundesliga-data-shootout/test/019d5b34_1.mp4\n",
      "../input/dfl-bundesliga-data-shootout/test/0b1495d3_0.mp4\n",
      "../input/dfl-bundesliga-data-shootout/test/0b1495d3_1.mp4\n",
      "../input/dfl-bundesliga-data-shootout/test/160606be_0.mp4\n",
      "../input/dfl-bundesliga-data-shootout/test/160606be_1.mp4\n",
      "../input/dfl-bundesliga-data-shootout/test/2f54ed1c_0.mp4\n",
      "../input/dfl-bundesliga-data-shootout/test/2f54ed1c_1.mp4\n",
      "../input/dfl-bundesliga-data-shootout/test/4dae79a9_0.mp4\n",
      "../input/dfl-bundesliga-data-shootout/test/4dae79a9_1.mp4\n",
      "../input/dfl-bundesliga-data-shootout/test/5dc4fe12_0.mp4\n",
      "../input/dfl-bundesliga-data-shootout/test/5dc4fe12_1.mp4\n",
      "../input/dfl-bundesliga-data-shootout/test/947e05ca_0.mp4\n",
      "../input/dfl-bundesliga-data-shootout/test/947e05ca_1.mp4\n",
      "../input/dfl-bundesliga-data-shootout/test/9a70c54e_0.mp4\n",
      "../input/dfl-bundesliga-data-shootout/test/9a70c54e_1.mp4\n",
      "../input/dfl-bundesliga-data-shootout/test/9d3c239b_0.mp4\n",
      "../input/dfl-bundesliga-data-shootout/test/9d3c239b_1.mp4\n",
      "../input/dfl-bundesliga-data-shootout/test/9f4df856_0.mp4\n",
      "../input/dfl-bundesliga-data-shootout/test/9f4df856_1.mp4\n",
      "../input/dfl-bundesliga-data-shootout/test/b2939d3c_0.mp4\n",
      "../input/dfl-bundesliga-data-shootout/test/b2939d3c_1.mp4\n",
      "../input/dfl-bundesliga-data-shootout/test/e660601b_0.mp4\n",
      "../input/dfl-bundesliga-data-shootout/test/e660601b_1.mp4\n",
      "../input/dfl-bundesliga-data-shootout/test/e9d974aa_0.mp4\n",
      "../input/dfl-bundesliga-data-shootout/test/e9d974aa_1.mp4\n",
      "../input/dfl-bundesliga-data-shootout/test/ec9f4e2b_0.mp4\n",
      "../input/dfl-bundesliga-data-shootout/test/ec9f4e2b_1.mp4\n",
      "../input/dfl-bundesliga-data-shootout/test/ef4c2eb9_0.mp4\n",
      "../input/dfl-bundesliga-data-shootout/test/ef4c2eb9_1.mp4\n",
      "../input/dfl-bundesliga-data-shootout/test/fdf84965_0.mp4\n",
      "../input/dfl-bundesliga-data-shootout/test/fdf84965_1.mp4\n"
     ]
    }
   ],
   "source": [
    "def extract_images(video_path, out_dir):\n",
    "    video_name = os.path.basename(video_path).split('.')[0]\n",
    "    cam = cv2.VideoCapture(video_path)\n",
    "    print(video_path)\n",
    "    frame_count = 1\n",
    "    while True:\n",
    "        successed, img = cam.read()\n",
    "        if not successed:\n",
    "            break\n",
    "        outfile = f'{out_dir}/{video_name}-{frame_count:06}.jpg'\n",
    "        img = cv2.resize(img, dsize=IMG_SIZE)\n",
    "        cv2.imwrite(outfile, img)\n",
    "        frame_count += 1    \n",
    "            \n",
    "IMG_SIZE = (300, 300)\n",
    "\n",
    "if TEST:\n",
    "    OUT_DIR = '../work/extracted_images_test'\n",
    "    IN_DIR = '../input/dfl-bundesliga-data-shootout/test'\n",
    "    IN_VIDEOS = sorted(glob.glob('../input/dfl-bundesliga-data-shootout/test/*'))\n",
    "    !mkdir -p $OUT_DIR\n",
    "    for video_path in IN_VIDEOS:\n",
    "        extract_images(video_path, OUT_DIR)\n",
    "    \n",
    "\n",
    "if VALID:\n",
    "    OUT_DIR = '../work/extracted_images_train'\n",
    "    IN_DIR = '../input/dfl-bundesliga-data-shootout/train'\n",
    "    IN_VIDEOS = ['../input/dfl-bundesliga-data-shootout/train/3c993bd2_0.mp4','../input/dfl-bundesliga-data-shootout/train/3c993bd2_1.mp4']\n",
    "    !mkdir -p $OUT_DIR\n",
    "    for video_path in IN_VIDEOS:\n",
    "        extract_images(video_path, OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "912696fd",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-08-22T23:40:01.470938Z",
     "iopub.status.busy": "2022-08-22T23:40:01.470551Z",
     "iopub.status.idle": "2022-08-22T23:40:04.459980Z",
     "shell.execute_reply": "2022-08-22T23:40:04.458417Z"
    },
    "papermill": {
     "duration": 2.999803,
     "end_time": "2022-08-22T23:40:04.463308",
     "exception": false,
     "start_time": "2022-08-22T23:40:01.463505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "torch.backends.cudnn.benchmark = True\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class DFLDataset(Dataset):\n",
    "    def __init__(self, img_path, img_label, transform=None):\n",
    "        self.img_path = img_path\n",
    "        self.img_label = img_label\n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = None\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = cv2.imread(self.img_path[index])\n",
    "        img = img.astype(np.float32)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, torch.from_numpy(np.array(self.img_label[index]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "    \n",
    "MODEL_PATH = '../input/dfl-frame-training-english/model.pth'\n",
    "def inference(path):\n",
    "    model = models.resnet18(False)\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(p=0.5, inplace=True),\n",
    "        nn.Linear(in_features=512, out_features=4, bias=True)\n",
    "    )\n",
    "    model.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "    model = model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    test_path = glob.glob(path + '*')\n",
    "    test_dataset = DFLDataset(test_path, [0] * len(test_path),\n",
    "        A.Compose([\n",
    "              A.Resize(300, 300),\n",
    "              A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "              ToTensorV2(),\n",
    "              ])\n",
    "    )\n",
    "    \n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=10, shuffle=False, num_workers=4, pin_memory=False\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    k = 3\n",
    "    end = time.time()\n",
    "    prob = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (input, _) in enumerate(loader):\n",
    "            input = input.cuda()\n",
    "            labels = model(input)\n",
    "            prob.append(labels.cpu().numpy())\n",
    "\n",
    "            if batch_idx % 10000 == 0:\n",
    "                print(batch_idx, len(test_dataset))\n",
    "\n",
    "    prob = np.concatenate(prob, axis=0)\n",
    "    return prob, [os.path.basename(x) for x in test_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e81c026a",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-08-22T23:40:04.482439Z",
     "iopub.status.busy": "2022-08-22T23:40:04.481955Z",
     "iopub.status.idle": "2022-08-22T23:40:04.488904Z",
     "shell.execute_reply": "2022-08-22T23:40:04.487179Z"
    },
    "papermill": {
     "duration": 0.021276,
     "end_time": "2022-08-22T23:40:04.493373",
     "exception": false,
     "start_time": "2022-08-22T23:40:04.472097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if VALID:\n",
    "    path = '../work/extracted_images_train/'\n",
    "    prob_train, filenames_train = inference(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a05757de",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-08-22T23:40:04.513458Z",
     "iopub.status.busy": "2022-08-22T23:40:04.512660Z",
     "iopub.status.idle": "2022-08-22T23:42:50.675803Z",
     "shell.execute_reply": "2022-08-22T23:42:50.674230Z"
    },
    "papermill": {
     "duration": 166.176587,
     "end_time": "2022-08-22T23:42:50.679150",
     "exception": false,
     "start_time": "2022-08-22T23:40:04.502563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 24000\n"
     ]
    }
   ],
   "source": [
    "if TEST:\n",
    "    path = '../work/extracted_images_test/'\n",
    "    prob_test, filenames_test = inference(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7017199d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T23:42:50.692662Z",
     "iopub.status.busy": "2022-08-22T23:42:50.692221Z",
     "iopub.status.idle": "2022-08-22T23:42:50.711523Z",
     "shell.execute_reply": "2022-08-22T23:42:50.710192Z"
    },
    "papermill": {
     "duration": 0.029125,
     "end_time": "2022-08-22T23:42:50.714151",
     "exception": false,
     "start_time": "2022-08-22T23:42:50.685026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "err_tol = {\n",
    "    'challenge': [ 0.30, 0.40, 0.50, 0.60, 0.70 ],\n",
    "    'play': [ 0.15, 0.20, 0.25, 0.30, 0.35 ],\n",
    "    'throwin': [ 0.15, 0.20, 0.25, 0.30, 0.35 ]\n",
    "}\n",
    "video_id_split = {\n",
    "    'val':[\n",
    "         '3c993bd2_0',\n",
    "         '3c993bd2_1',\n",
    "    ],\n",
    "    'train':[\n",
    "         '1606b0e6_0',\n",
    "         '1606b0e6_1',\n",
    "         '35bd9041_0',\n",
    "         '35bd9041_1',\n",
    "         '407c5a9e_1',\n",
    "         '4ffd5986_0',\n",
    "         '9a97dae4_1',\n",
    "         'cfbe2e94_0',\n",
    "         'cfbe2e94_1',\n",
    "         'ecf251d4_0',\n",
    "    ]\n",
    "}\n",
    "event_names = ['challenge', 'throwin', 'play']\n",
    "label_dict = {\n",
    "    'background':0,\n",
    "    'challenge':1,\n",
    "    'play':2,\n",
    "    'throwin':3,\n",
    "}\n",
    "event_names_with_background = ['background','challenge','play','throwin']\n",
    "\n",
    "\n",
    "def make_sub(prob, filenames):\n",
    "    \n",
    "    frame_rate = 25\n",
    "    window_size = 10\n",
    "    ignore_width = 10\n",
    "    group_count = 5\n",
    "\n",
    "    df = pd.DataFrame(prob,columns=event_names_with_background)\n",
    "    df['video_name'] = filenames\n",
    "    df['video_id'] = df['video_name'].str.split('-').str[0]\n",
    "    df['frame_id'] = df['video_name'].str.split('-').str[1].str.split('.').str[0].astype(int)\n",
    "\n",
    "    train_df = pd.DataFrame()\n",
    "    for video_id,gdf in df.groupby('video_id'):\n",
    "        for i, event in enumerate(event_names):\n",
    "            #print(video_id, event)\n",
    "            prob_arr = gdf[event].rolling(window=window_size, center=True).mean().fillna(-100).values\n",
    "            gdf['rolling_prob'] = prob_arr\n",
    "\n",
    "\n",
    "            sort_arr = np.argsort(-prob_arr)\n",
    "            rank_arr = np.empty_like(sort_arr)\n",
    "            rank_arr[sort_arr] = np.arange(len(sort_arr))\n",
    "            idx_list = []\n",
    "            for i in range(len(prob_arr)):\n",
    "                this_idx = sort_arr[i]\n",
    "                if this_idx >= 0:\n",
    "                    idx_list.append(this_idx)\n",
    "                    for parity in (-1,1):\n",
    "                        for j in range(1, ignore_width+1):\n",
    "                            ex_idx = this_idx + j * parity\n",
    "                            if ex_idx >= 0 and ex_idx < len(prob_arr):\n",
    "                                sort_arr[rank_arr[ex_idx]] = -1\n",
    "            this_df = gdf.iloc[idx_list].reset_index(drop=True).reset_index().rename(columns={'index':'rank'})[['rank','video_id','frame_id']]\n",
    "            this_df['event'] = event\n",
    "            train_df = train_df.append(this_df)  \n",
    "    \n",
    "    train_df['time'] = train_df['frame_id']/25\n",
    "    train_df['score'] = 1/(train_df['rank']+1)\n",
    "    \n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f42c9154",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-08-22T23:42:50.727032Z",
     "iopub.status.busy": "2022-08-22T23:42:50.726706Z",
     "iopub.status.idle": "2022-08-22T23:42:50.783396Z",
     "shell.execute_reply": "2022-08-22T23:42:50.782008Z"
    },
    "papermill": {
     "duration": 0.066555,
     "end_time": "2022-08-22T23:42:50.786201",
     "exception": false,
     "start_time": "2022-08-22T23:42:50.719646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# copy from https://www.kaggle.com/code/ryanholbrook/competition-metric-dfl-event-detection-ap\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.testing import assert_index_equal\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "tolerances = {\n",
    "    \"challenge\": [0.3, 0.4, 0.5, 0.6, 0.7],\n",
    "    \"play\": [0.15, 0.20, 0.25, 0.30, 0.35],\n",
    "    \"throwin\": [0.15, 0.20, 0.25, 0.30, 0.35],\n",
    "}\n",
    "            \n",
    "\n",
    "def filter_detections(\n",
    "        detections: pd.DataFrame, intervals: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Drop detections not inside a scoring interval.\"\"\"\n",
    "    detection_time = detections.loc[:, 'time'].sort_values().to_numpy()\n",
    "    intervals = intervals.to_numpy()\n",
    "    is_scored = np.full_like(detection_time, False, dtype=bool)\n",
    "\n",
    "    i, j = 0, 0\n",
    "    while i < len(detection_time) and j < len(intervals):\n",
    "        time = detection_time[i]\n",
    "        int_ = intervals[j]\n",
    "\n",
    "        # If the detection is prior in time to the interval, go to the next detection.\n",
    "        if time < int_.left:\n",
    "            i += 1\n",
    "        # If the detection is inside the interval, keep it and go to the next detection.        \n",
    "        elif time in int_:\n",
    "            is_scored[i] = True\n",
    "            i += 1\n",
    "        # If the detection is later in time, go to the next interval.\n",
    "        else:\n",
    "            j += 1\n",
    "\n",
    "    return detections.loc[is_scored].reset_index(drop=True)\n",
    "\n",
    "\n",
    "def match_detections(\n",
    "        tolerance: float, ground_truths: pd.DataFrame, detections: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Match detections to ground truth events. Arguments are taken from a common event x tolerance x video evaluation group.\"\"\"\n",
    "    detections_sorted = detections.sort_values('score', ascending=False).dropna()\n",
    "\n",
    "    is_matched = np.full_like(detections_sorted['event'], False, dtype=bool)\n",
    "    gts_matched = set()\n",
    "    for i, det in enumerate(detections_sorted.itertuples(index=False)):\n",
    "        best_error = tolerance\n",
    "        best_gt = None\n",
    "\n",
    "        for gt in ground_truths.itertuples(index=False):\n",
    "            error = abs(det.time - gt.time)\n",
    "            if error < best_error and not gt in gts_matched:\n",
    "                best_gt = gt\n",
    "                best_error = error\n",
    "            \n",
    "        if best_gt is not None:\n",
    "            is_matched[i] = True\n",
    "            gts_matched.add(best_gt)\n",
    "\n",
    "    detections_sorted['matched'] = is_matched\n",
    "\n",
    "    return detections_sorted\n",
    "\n",
    "\n",
    "def precision_recall_curve(\n",
    "        matches: np.ndarray, scores: np.ndarray, p: int\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    if len(matches) == 0:\n",
    "        return [1], [0], []\n",
    "\n",
    "    # Sort matches by decreasing confidence\n",
    "    idxs = np.argsort(scores, kind='stable')[::-1]\n",
    "    scores = scores[idxs]\n",
    "    matches = matches[idxs]\n",
    "    \n",
    "    distinct_value_indices = np.where(np.diff(scores))[0]\n",
    "    threshold_idxs = np.r_[distinct_value_indices, matches.size - 1]\n",
    "    thresholds = scores[threshold_idxs]\n",
    "    \n",
    "    # Matches become TPs and non-matches FPs as confidence threshold decreases\n",
    "    tps = np.cumsum(matches)[threshold_idxs]\n",
    "    fps = np.cumsum(~matches)[threshold_idxs]\n",
    "    \n",
    "    precision = tps / (tps + fps)\n",
    "    precision[np.isnan(precision)] = 0\n",
    "    recall = tps / p  # total number of ground truths might be different than total number of matches\n",
    "    \n",
    "    # Stop when full recall attained and reverse the outputs so recall is non-increasing.\n",
    "    last_ind = tps.searchsorted(tps[-1])\n",
    "    sl = slice(last_ind, None, -1)\n",
    "\n",
    "    # Final precision is 1 and final recall is 0\n",
    "    return np.r_[precision[sl], 1], np.r_[recall[sl], 0], thresholds[sl]\n",
    "\n",
    "\n",
    "def average_precision_score(matches: np.ndarray, scores: np.ndarray, p: int) -> float:\n",
    "    precision, recall, _ = precision_recall_curve(matches, scores, p)\n",
    "    # Compute step integral\n",
    "    return -np.sum(np.diff(recall) * np.array(precision)[:-1])\n",
    "\n",
    "\n",
    "def event_detection_ap(\n",
    "        solution: pd.DataFrame,\n",
    "        submission: pd.DataFrame,\n",
    "        tolerances: Dict[str, float],\n",
    ") -> float:\n",
    "\n",
    "    assert_index_equal(solution.columns, pd.Index(['video_id', 'time', 'event']))\n",
    "    assert_index_equal(submission.columns, pd.Index(['video_id', 'time', 'event', 'score']))\n",
    "\n",
    "    # Ensure solution and submission are sorted properly\n",
    "    solution = solution.sort_values(['video_id', 'time'])\n",
    "    submission = submission.sort_values(['video_id', 'time'])\n",
    "    \n",
    "    # Extract scoring intervals.\n",
    "    intervals = (\n",
    "        solution\n",
    "        .query(\"event in ['start', 'end']\")\n",
    "        .assign(interval=lambda x: x.groupby(['video_id', 'event']).cumcount())\n",
    "        .pivot(index='interval', columns=['video_id', 'event'], values='time')\n",
    "        .stack('video_id')\n",
    "        .swaplevel()\n",
    "        .sort_index()\n",
    "        .loc[:, ['start', 'end']]\n",
    "        .apply(lambda x: pd.Interval(*x, closed='both'), axis=1)\n",
    "    )\n",
    "\n",
    "    # Extract ground-truth events.\n",
    "    ground_truths = (\n",
    "        solution\n",
    "        .query(\"event not in ['start', 'end']\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Map each event class to its prevalence (needed for recall calculation)\n",
    "    class_counts = ground_truths.value_counts('event').to_dict()\n",
    "\n",
    "    # Create table for detections with a column indicating a match to a ground-truth event\n",
    "    detections = submission.assign(matched = False)\n",
    "\n",
    "    # Remove detections outside of scoring intervals\n",
    "    detections_filtered = []\n",
    "    for (det_group, dets), (int_group, ints) in zip(\n",
    "        detections.groupby('video_id'), intervals.groupby('video_id')\n",
    "    ):\n",
    "        assert det_group == int_group\n",
    "        detections_filtered.append(filter_detections(dets, ints))\n",
    "    detections_filtered = pd.concat(detections_filtered, ignore_index=True)\n",
    "\n",
    "    # Create table of event-class x tolerance x video_id values\n",
    "    aggregation_keys = pd.DataFrame(\n",
    "        [(ev, tol, vid)\n",
    "         for ev in tolerances.keys()\n",
    "         for tol in tolerances[ev]\n",
    "         for vid in ground_truths['video_id'].unique()],\n",
    "        columns=['event', 'tolerance', 'video_id'],\n",
    "    )\n",
    "\n",
    "    # Create match evaluation groups: event-class x tolerance x video_id\n",
    "    detections_grouped = (\n",
    "        aggregation_keys\n",
    "        .merge(detections_filtered, on=['event', 'video_id'], how='left')\n",
    "        .groupby(['event', 'tolerance', 'video_id'])\n",
    "    )\n",
    "    ground_truths_grouped = (\n",
    "        aggregation_keys\n",
    "        .merge(ground_truths, on=['event', 'video_id'], how='left')\n",
    "        .groupby(['event', 'tolerance', 'video_id'])\n",
    "    )\n",
    "    \n",
    "    # Match detections to ground truth events by evaluation group\n",
    "    detections_matched = []\n",
    "    for key in aggregation_keys.itertuples(index=False):\n",
    "        dets = detections_grouped.get_group(key)\n",
    "        gts = ground_truths_grouped.get_group(key)\n",
    "        detections_matched.append(\n",
    "            match_detections(dets['tolerance'].iloc[0], gts, dets)\n",
    "        )\n",
    "    detections_matched = pd.concat(detections_matched)\n",
    "    \n",
    "    # Compute AP per event x tolerance group\n",
    "    event_classes = ground_truths['event'].unique()\n",
    "    ap_table = (\n",
    "        detections_matched\n",
    "        .query(\"event in @event_classes\")\n",
    "        .groupby(['event', 'tolerance']).apply(\n",
    "        lambda group: average_precision_score(\n",
    "        group['matched'].to_numpy(),\n",
    "                group['score'].to_numpy(),\n",
    "                class_counts[group['event'].iat[0]],\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Average over tolerances, then over event classes\n",
    "    mean_ap = ap_table.groupby('event').mean().mean()\n",
    "\n",
    "    return mean_ap\n",
    "\n",
    "solution = pd.read_csv(\"../input/dfl-bundesliga-data-shootout/train.csv\", usecols=['video_id', 'time', 'event'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b663cf25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T23:42:50.798677Z",
     "iopub.status.busy": "2022-08-22T23:42:50.798260Z",
     "iopub.status.idle": "2022-08-22T23:42:50.804456Z",
     "shell.execute_reply": "2022-08-22T23:42:50.803052Z"
    },
    "papermill": {
     "duration": 0.015755,
     "end_time": "2022-08-22T23:42:50.807244",
     "exception": false,
     "start_time": "2022-08-22T23:42:50.791489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if VALID:\n",
    "    train_df = make_sub(prob_train, filenames_train)\n",
    "    score = event_detection_ap(solution[solution['video_id'].isin(train_df['video_id'].unique())], \n",
    "                               train_df[['video_id', 'time', 'event', 'score']], tolerances)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f92623c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T23:42:50.819935Z",
     "iopub.status.busy": "2022-08-22T23:42:50.818684Z",
     "iopub.status.idle": "2022-08-22T23:42:51.498202Z",
     "shell.execute_reply": "2022-08-22T23:42:51.496838Z"
    },
    "papermill": {
     "duration": 0.688685,
     "end_time": "2022-08-22T23:42:51.501163",
     "exception": false,
     "start_time": "2022-08-22T23:42:50.812478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    test_df = make_sub(prob_test, filenames_test)\n",
    "    test_df[['video_id', 'time', 'event', 'score']].to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 553.260714,
   "end_time": "2022-08-22T23:42:53.900821",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-22T23:33:40.640107",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
